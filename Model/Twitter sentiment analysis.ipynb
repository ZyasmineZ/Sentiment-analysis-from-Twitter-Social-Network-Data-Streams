{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c55ad7-1494-4c0c-8166-62a42f70e149",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed17d42-a3ff-44b4-9d97-f52649342388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import time\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType, FloatType\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StringIndexer, CountVectorizer, NGram, VectorAssembler, ChiSqSelector\n",
    "from pyspark.sql.functions import col, sum as spark_sum, split, concat_ws, udf\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, sum as spark_sum, split, concat_ws, udf\n",
    "import string\n",
    "from pyspark.ml.feature import StopWordsRemover, StringIndexer, CountVectorizer, IDF, Tokenizer, HashingTF\n",
    "import re\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376f446-8f91-4f75-b8c3-d2c469c2164a",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Variables de contexte</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebdb827-dd5c-4afd-a4c1-9f105115dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark1 = SparkSession.builder\\\n",
    "            .master(\"local[16]\")\\\n",
    "            .appName(\"LR_Twitter\")\\\n",
    "            .getOrCreate()\n",
    "\n",
    "path = \"twitter_training.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Tweet ID\", IntegerType(), True),\n",
    "    StructField(\"Entity\", StringType(), True),\n",
    "    StructField(\"Sentiment\", StringType(), True),\n",
    "    StructField(\"Tweet content\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0944868e-5bce-4f41-bd9a-c1189f50894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark1.read.csv(path,\n",
    "                     inferSchema=True,\n",
    "                     header=False,\n",
    "                     schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baf230b-8358-400f-9a90-e54f7e8f4038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------+--------------------+\n",
      "|Tweet ID|     Entity|Sentiment|       Tweet content|\n",
      "+--------+-----------+---------+--------------------+\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|I am coming to th...|\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|im coming on bord...|\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|im getting into b...|\n",
      "|    2402|Borderlands| Positive|So I spent a few ...|\n",
      "|    2402|Borderlands| Positive|So I spent a coup...|\n",
      "|    2402|Borderlands| Positive|So I spent a few ...|\n",
      "|    2402|Borderlands| Positive|So I spent a few ...|\n",
      "|    2402|Borderlands| Positive|2010 So I spent a...|\n",
      "|    2402|Borderlands| Positive|                 was|\n",
      "|    2403|Borderlands|  Neutral|Rock-Hard La Varl...|\n",
      "|    2403|Borderlands|  Neutral|Rock-Hard La Varl...|\n",
      "|    2403|Borderlands|  Neutral|Rock-Hard La Varl...|\n",
      "|    2403|Borderlands|  Neutral|Rock-Hard La Vita...|\n",
      "|    2403|Borderlands|  Neutral|Live Rock - Hard ...|\n",
      "|    2403|Borderlands|  Neutral|I-Hard like me, R...|\n",
      "|    2404|Borderlands| Positive|that was the firs...|\n",
      "|    2404|Borderlands| Positive|this was the firs...|\n",
      "+--------+-----------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82917f4f-5f4d-4126-854b-cc4ec024c7e7",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Data cleaning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2370301d-0162-40be-bfb6-e2c5751e706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------+-------------+\n",
      "|Tweet ID|Entity|Sentiment|Tweet content|\n",
      "+--------+------+---------+-------------+\n",
      "|       0|     0|        0|          686|\n",
      "+--------+------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting null values in each column\n",
    "null_counts = df.select(*(spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns))\n",
    "\n",
    "# Displaying the count of null values in each column\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5920c9-2619-4815-bcda-9b318a930c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------+-------------+\n",
      "|Tweet ID|Entity|Sentiment|Tweet content|\n",
      "+--------+------+---------+-------------+\n",
      "|       0|     0|        0|            0|\n",
      "+--------+------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with null values\n",
    "df = df.na.drop()\n",
    "\n",
    "# Checking for null values after dropping\n",
    "null_counts = df.select(*(spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns))\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94c2f8a-66d6-4449-9bac-ec433fb8a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with null values in 'Tweet content' column:\n",
      "+--------+------+---------+-------------+\n",
      "|Tweet ID|Entity|Sentiment|Tweet content|\n",
      "+--------+------+---------+-------------+\n",
      "+--------+------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out rows with null values in the \"Tweet content\" column\n",
    "print(\"Rows with null values in 'Tweet content' column:\")\n",
    "df.filter(col(\"Tweet content\").isNull()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea93858-e267-4091-9859-01711d5114e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 1989\n"
     ]
    }
   ],
   "source": [
    "# Counting duplicated rows\n",
    "duplicated_count = df.groupBy(df.columns).count().where(col(\"count\") > 1).count()\n",
    "\n",
    "print(\"Number of duplicated rows:\", duplicated_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98eb304-ef3c-45bd-98a0-ffab149d00c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicates\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# Checking for duplicated rows after dropping\n",
    "duplicated_count = df.groupBy(df.columns).count().where(col(\"count\") > 1).count()\n",
    "\n",
    "print(\"Number of duplicated rows after dropping:\", duplicated_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6cd62f-7bcf-4c46-8e37-3b67007bcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with null or empty values in the \"Tweet content\" column\n",
    "df = df.filter((col(\"Tweet content\").isNotNull()) & (col(\"Tweet content\") != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048d20c8-9110-409c-9caf-454b820d005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_string(df, column):\n",
    "    \"\"\"\n",
    "    Filter out rows with non-string values in the specified column.\n",
    "    Convert non-string values to strings.\n",
    "    \"\"\"\n",
    "    # Drop rows with null values in the specified column\n",
    "    df = df.dropna(subset=[column])\n",
    "    \n",
    "    # Convert non-string values to strings in the specified column\n",
    "    df = df.withColumn(column, col(column).cast(\"string\"))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c9ceb2f-a126-4efd-89ff-f4d2047e8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(df, column):\n",
    "    \"\"\"Convert text in the specified column to lowercase.\"\"\"\n",
    "    df = df.withColumn(column, lower(col(column)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6ddc94-8573-4047-951e-fc6b437bce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(df, column):\n",
    "    \"\"\"Remove HTML tags from text in the specified column.\"\"\"\n",
    "    df = df.withColumn(column, regexp_replace(col(column), '<.*?>', ''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4592a9c1-6060-46e9-aea7-cc6695c35e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(df, column):\n",
    "    \"\"\"Remove URLs or hyperlinks from text in the specified column.\"\"\"\n",
    "    df = df.withColumn(column, regexp_replace(col(column), 'http\\\\S+|www\\\\S+', ''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac92e27-afc6-411e-9f1d-66c303934185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(df, column):\n",
    "    \"\"\"Exclude numerical digits from text in the specified column.\"\"\"\n",
    "    df = df.withColumn(column, regexp_replace(col(column), '\\\\d+', ''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af5f28e3-aaa8-4fa2-8455-926e95fedc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(df, column):\n",
    "    \"\"\"Remove punctuation marks from text in the specified column.\"\"\"\n",
    "    # Define regular expression pattern to match punctuation marks\n",
    "    punctuation_pattern = \"[\" + re.escape(string.punctuation) + \"]\"\n",
    "    # Remove punctuation marks using regexp_replace\n",
    "    df = df.withColumn(column, regexp_replace(col(column), punctuation_pattern, ''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ee080c-4956-4031-879f-b9c368a997ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df, column):\n",
    "    \"\"\"Eliminate common stopwords from the tokenized text in the specified column.\"\"\"\n",
    "    remover = StopWordsRemover(inputCol=column, outputCol=column+\"_filtered\")\n",
    "    df = remover.transform(df).drop(column)\n",
    "    df = df.withColumnRenamed(column+\"_filtered\", column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eecae3d-bf1f-44aa-9646-6944dc23f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(df, column):\n",
    "    \"\"\"Remove emojis from the text in the specified column.\"\"\"\n",
    "    emoji_pattern = \"[\" + u\"\\U0001F600-\\U0001F64F\" + u\"\\U0001F300-\\U0001F5FF\" + u\"\\U0001F680-\\U0001F6FF\" + u\"\\U0001F1E0-\\U0001F1FF\" + u\"\\U00002500-\\U00002BEF\" + u\"\\U00002702-\\U000027B0\" + u\"\\U000024C2-\\U0001F251\" + u\"\\U0001f926-\\U0001f937\" + u\"\\U00010000-\\U0010ffff\" + u\"\\u2640-\\u2642\" + u\"\\u2600-\\u2B55\" + u\"\\u200d\" + u\"\\u23cf\" + u\"\\u23e9\" + u\"\\u231a\" + u\"\\ufe0f\" + u\"\\u3030\" + \"]+\"\n",
    "    # Join array of strings into a single string\n",
    "    df = df.withColumn(column, concat_ws(\" \", col(column)))\n",
    "    # Remove emojis from the text\n",
    "    df = df.withColumn(column, regexp_replace(col(column), emoji_pattern, ''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a49efa9d-6459-4c00-9d7f-7da9f030116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------+--------------------+\n",
      "|Tweet ID|              Entity| Sentiment|       Tweet content|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "|    2504|         Borderlands|  Positive|    im so fucking in|\n",
      "|    2600|         Borderlands|  Positive|i want to say tha...|\n",
      "|    2716|         Borderlands|   Neutral|this would be an ...|\n",
      "|    2729|         Borderlands|   Neutral|back on my dry bo...|\n",
      "|    2741|         Borderlands|  Positive|been mad inactive...|\n",
      "|    2763|         Borderlands|  Negative|not to say that t...|\n",
      "|    1614|CallOfDutyBlackop...|  Positive|this sounds like ...|\n",
      "|    1638|CallOfDutyBlackop...|  Negative|gonna fucking be ass|\n",
      "|    1700|CallOfDutyBlackop...|Irrelevant|you can’t say thi...|\n",
      "|    1715|CallOfDutyBlackop...|  Negative|i tried the new a...|\n",
      "|    1765|CallOfDutyBlackop...|  Positive|sooo hyped for wh...|\n",
      "|    1889|CallOfDutyBlackop...|Irrelevant|i give up too tir...|\n",
      "|    1913|CallOfDutyBlackop...|  Positive|wow they really w...|\n",
      "|     194|              Amazon|  Negative|im calling amazon...|\n",
      "|     195|              Amazon|  Negative|you a bought some...|\n",
      "|     212|              Amazon|Irrelevant|airtelpresence  w...|\n",
      "|     242|              Amazon|   Neutral|the premed  the b...|\n",
      "|     257|              Amazon|   Neutral|yall complain abo...|\n",
      "|     287|              Amazon|   Neutral|card against huma...|\n",
      "|     314|              Amazon|  Negative|please explain ho...|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(df):\n",
    "    df = filter_non_string(df, 'Tweet content')\n",
    "    df = normalize_text(df, 'Tweet content')\n",
    "    df = remove_html_tags(df, 'Tweet content')\n",
    "    df = remove_urls(df, 'Tweet content')\n",
    "    df = remove_numbers(df, 'Tweet content')\n",
    "    df = remove_punctuation(df, 'Tweet content')\n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "data_processed = preprocess_text(df)\n",
    "data_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b59320a-b13e-4907-9af8-54c230bab789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol=\"Tweet content\", outputCol=\"Tweet content_token\")\n",
    "data_processed = tokenizer.transform(data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dbec3e9-a71c-4bf2-a3c7-5af6d9563358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------+--------------------+--------------------+\n",
      "|Tweet ID|              Entity| Sentiment|       Tweet content| Tweet content_token|\n",
      "+--------+--------------------+----------+--------------------+--------------------+\n",
      "|    2504|         Borderlands|  Positive|    im so fucking in|          im fucking|\n",
      "|    2600|         Borderlands|  Positive|i want to say tha...|      want say thank|\n",
      "|    2716|         Borderlands|   Neutral|this would be an ...|amazing casting y...|\n",
      "|    2729|         Borderlands|   Neutral|back on my dry bo...|back dry borderla...|\n",
      "|    2741|         Borderlands|  Positive|been mad inactive...|mad inactive toda...|\n",
      "|    2763|         Borderlands|  Negative|not to say that t...|say older games f...|\n",
      "|    1614|CallOfDutyBlackop...|  Positive|this sounds like ...|sounds like reall...|\n",
      "|    1638|CallOfDutyBlackop...|  Negative|gonna fucking be ass|   gonna fucking ass|\n",
      "|    1700|CallOfDutyBlackop...|Irrelevant|you can’t say thi...|can’t say shit li...|\n",
      "|    1715|CallOfDutyBlackop...|  Negative|i tried the new a...|tried new auto sp...|\n",
      "|    1765|CallOfDutyBlackop...|  Positive|sooo hyped for wh...|sooo hyped love w...|\n",
      "|    1889|CallOfDutyBlackop...|Irrelevant|i give up too tir...|give tired rng ha...|\n",
      "|    1913|CallOfDutyBlackop...|  Positive|wow they really w...|wow really went r...|\n",
      "|     194|              Amazon|  Negative|im calling amazon...|im calling amazon...|\n",
      "|     195|              Amazon|  Negative|you a bought some...|bought fucking ai...|\n",
      "|     212|              Amazon|Irrelevant|airtelpresence  w...|airtelpresence  c...|\n",
      "|     242|              Amazon|   Neutral|the premed  the b...|premed  bull inte...|\n",
      "|     257|              Amazon|   Neutral|yall complain abo...|yall complain jef...|\n",
      "|     287|              Amazon|   Neutral|card against huma...|card humanity ep ...|\n",
      "|     314|              Amazon|  Negative|please explain ho...|please explain po...|\n",
      "+--------+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_tokens(df):\n",
    "    df = remove_stopwords(df, 'Tweet content_token')\n",
    "    df = remove_emojis(df, 'Tweet content_token')\n",
    "    return df\n",
    "\n",
    "data_processed = preprocess_tokens(data_processed)\n",
    "data_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b0a8fdd-89a0-4601-95ed-06fc37e6a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------+--------------------+\n",
      "|Tweet ID|              Entity| Sentiment|        Tweet tokens|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "|    2504|         Borderlands|  Positive|       [im, fucking]|\n",
      "|    2600|         Borderlands|  Positive|  [want, say, thank]|\n",
      "|    2716|         Borderlands|   Neutral|[amazing, casting...|\n",
      "|    2729|         Borderlands|   Neutral|[back, dry, borde...|\n",
      "|    2741|         Borderlands|  Positive|[mad, inactive, t...|\n",
      "|    2763|         Borderlands|  Negative|[say, older, game...|\n",
      "|    1614|CallOfDutyBlackop...|  Positive|[sounds, like, re...|\n",
      "|    1638|CallOfDutyBlackop...|  Negative|[gonna, fucking, ...|\n",
      "|    1700|CallOfDutyBlackop...|Irrelevant|[can’t, say, shit...|\n",
      "|    1715|CallOfDutyBlackop...|  Negative|[tried, new, auto...|\n",
      "|    1765|CallOfDutyBlackop...|  Positive|[sooo, hyped, lov...|\n",
      "|    1889|CallOfDutyBlackop...|Irrelevant|[give, tired, rng...|\n",
      "|    1913|CallOfDutyBlackop...|  Positive|[wow, really, wen...|\n",
      "|     194|              Amazon|  Negative|[im, calling, ama...|\n",
      "|     195|              Amazon|  Negative|[bought, fucking,...|\n",
      "|     212|              Amazon|Irrelevant|[airtelpresence, ...|\n",
      "|     242|              Amazon|   Neutral|[premed, , bull, ...|\n",
      "|     257|              Amazon|   Neutral|[yall, complain, ...|\n",
      "|     287|              Amazon|   Neutral|[card, humanity, ...|\n",
      "|     314|              Amazon|  Negative|[please, explain,...|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol=\"Tweet content_token\", outputCol=\"Tweet tokens\")\n",
    "data_processed = tokenizer.transform(data_processed)\n",
    "\n",
    "# Drop the original column \"Tweet content_token\"\n",
    "data_processed = data_processed.drop(\"Tweet content_token\")\n",
    "data_processed = data_processed.drop(\"Tweet content\")\n",
    "\n",
    "data_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca441f2-47fb-4a61-915a-af548fd2cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF vectorizer\n",
    "hashingTF = HashingTF(inputCol=\"Tweet tokens\", outputCol=\"rawFeatures\")\n",
    "\n",
    "# Transform the data\n",
    "featurizedData = hashingTF.transform(data_processed)\n",
    "\n",
    "# Initialize IDF vectorizer\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Fit and transform the data\n",
    "idfModel = idf.fit(featurizedData)\n",
    "tfidf_matrix = idfModel.transform(featurizedData)\n",
    "\n",
    "# Convert the sparse matrix to a dense array\n",
    "to_array = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n",
    "tfidf_array = tfidf_matrix.withColumn('features', to_array('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b78ccf98-7f36-47bc-b2f6-7bbab86dec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------+--------------------+\n",
      "|Tweet ID|              Entity| Sentiment|        Tweet tokens|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "|    2504|         Borderlands|  Positive|       [im, fucking]|\n",
      "|    2600|         Borderlands|  Positive|  [want, say, thank]|\n",
      "|    2716|         Borderlands|   Neutral|[amazing, casting...|\n",
      "|    2729|         Borderlands|   Neutral|[back, dry, borde...|\n",
      "|    2741|         Borderlands|  Positive|[mad, inactive, t...|\n",
      "|    2763|         Borderlands|  Negative|[say, older, game...|\n",
      "|    1614|CallOfDutyBlackop...|  Positive|[sounds, like, re...|\n",
      "|    1638|CallOfDutyBlackop...|  Negative|[gonna, fucking, ...|\n",
      "|    1700|CallOfDutyBlackop...|Irrelevant|[can’t, say, shit...|\n",
      "|    1715|CallOfDutyBlackop...|  Negative|[tried, new, auto...|\n",
      "|    1765|CallOfDutyBlackop...|  Positive|[sooo, hyped, lov...|\n",
      "|    1889|CallOfDutyBlackop...|Irrelevant|[give, tired, rng...|\n",
      "|    1913|CallOfDutyBlackop...|  Positive|[wow, really, wen...|\n",
      "|     194|              Amazon|  Negative|[im, calling, ama...|\n",
      "|     195|              Amazon|  Negative|[bought, fucking,...|\n",
      "|     212|              Amazon|Irrelevant|[airtelpresence, ...|\n",
      "|     242|              Amazon|   Neutral|[premed, , bull, ...|\n",
      "|     257|              Amazon|   Neutral|[yall, complain, ...|\n",
      "|     287|              Amazon|   Neutral|[card, humanity, ...|\n",
      "|     314|              Amazon|  Negative|[please, explain,...|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6bc5d79-43da-4fa4-ae5f-92f0165965ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------+--------------------+\n",
      "|Tweet ID|              Entity| Sentiment|       Tweet content|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "|    2504|         Borderlands|  Positive|       [im, fucking]|\n",
      "|    2600|         Borderlands|  Positive|  [want, say, thank]|\n",
      "|    2716|         Borderlands|   Neutral|[amazing, casting...|\n",
      "|    2729|         Borderlands|   Neutral|[back, dry, borde...|\n",
      "|    2741|         Borderlands|  Positive|[mad, inactive, t...|\n",
      "|    2763|         Borderlands|  Negative|[say, older, game...|\n",
      "|    1614|CallOfDutyBlackop...|  Positive|[sounds, like, re...|\n",
      "|    1638|CallOfDutyBlackop...|  Negative|[gonna, fucking, ...|\n",
      "|    1700|CallOfDutyBlackop...|Irrelevant|[can’t, say, shit...|\n",
      "|    1715|CallOfDutyBlackop...|  Negative|[tried, new, auto...|\n",
      "|    1765|CallOfDutyBlackop...|  Positive|[sooo, hyped, lov...|\n",
      "|    1889|CallOfDutyBlackop...|Irrelevant|[give, tired, rng...|\n",
      "|    1913|CallOfDutyBlackop...|  Positive|[wow, really, wen...|\n",
      "|     194|              Amazon|  Negative|[im, calling, ama...|\n",
      "|     195|              Amazon|  Negative|[bought, fucking,...|\n",
      "|     212|              Amazon|Irrelevant|[airtelpresence, ...|\n",
      "|     242|              Amazon|   Neutral|[premed, , bull, ...|\n",
      "|     257|              Amazon|   Neutral|[yall, complain, ...|\n",
      "|     287|              Amazon|   Neutral|[card, humanity, ...|\n",
      "|     314|              Amazon|  Negative|[please, explain,...|\n",
      "+--------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_processed = data_processed.withColumnRenamed(\"Tweet tokens\", \"Tweet content\") \\\n",
    "                               .withColumnRenamed(\"EntityIndex\", \"Entity\") \\\n",
    "                               .withColumnRenamed(\"SentimentIndex\", \"Sentiment\")\n",
    "\n",
    "# Show the renamed DataFrame\n",
    "data_processed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e16ad-a436-4816-96f0-b8788619a949",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Chargement du dataset et séparation train/test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad614699-5d8d-4b59-9521-5e1f09f4bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train, test = tfidf_matrix.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Fit the model\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='SentimentIndex')\n",
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e595a-23d3-4fc8-bc2b-cf31d7d93bd7",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">HashingTF - IDF (paramètres par défaut)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e4f093-373c-411d-bc98-faa62fb13dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtf = HashingTF(inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\")\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"Sentiment\", outputCol = \"label\")\n",
    "\n",
    "lr = LogisticRegression()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[hashtf, idf, label_stringIdx, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0f641f-248c-4698-8fe0-7024a0500529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "<timed exec>:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:03:01.070135\n",
      "Accuracy: 0.8295262267343486\n",
      "Precision: 0.8295932053518089\n",
      "Recall: 0.8295262267343486\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "st = datetime.utcnow()\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "print('Training time:', datetime.utcnow() - st)\n",
    "\n",
    "predictions = pipelineFit.transform(test_set)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad060151-fdbd-492d-a021-11dee7337861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: model\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# Assuming 'pipelineFit' is your trained PipelineModel\n",
    "model_path = \"model\" \n",
    "pipelineFit.save(model_path)\n",
    "\n",
    "print(\"Model saved successfully at:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f212f2f-80bb-4556-9616-c61db874e18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
